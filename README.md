# Airflow Pipeline: Customer Requests Ingestion

This project implements an Apache Airflow pipeline that ingests **customer request data** from CSV files, processes them, and loads them into a **PostgreSQL database** for downstream analytics.

## ðŸ“Œ Features
- Airflow DAG for **extract â†’ transform â†’ load (ETL)** of customer requests.
- Source data: CSV files (raw â†’ processed â†’ cleaned).
- Target database: PostgreSQL (`support.customer_requests` table).
- Configurable schema and manifest YAML files for flexibility.

## ðŸ“‚ Repository Structure

airflow-pipeline/
â”‚â”€â”€ dags/
â”‚    â””â”€â”€ extraction/customer_requests/
â”‚        â”œâ”€â”€ customer_requests_pipeline.py
â”‚        â”œâ”€â”€ ddl.sql
â”‚        â”œâ”€â”€ load.sql
â”‚        â”œâ”€â”€ schema.sql
â”‚        â”œâ”€â”€ schema.yaml
â”‚        â””â”€â”€ dataset_manifest.yaml
â”‚â”€â”€ data/
â”‚    â””â”€â”€ raw/          # Drop raw CSVs here
â”‚    â””â”€â”€ processed/    # Cleaned CSVs land here
â”‚â”€â”€ docker-compose.yaml
â”‚â”€â”€ logs
â”‚â”€â”€ .env
â”‚â”€â”€ .gitignore
â”‚â”€â”€ README.md


## âš¡ Prerequisites
- [Docker](https://docs.docker.com/get-docker/) & Docker Compose
- Git
- (Optional) [pgAdmin](https://www.pgadmin.org/) or any Postgres client

## ðŸš€ Quickstart
```bash
# Clone the repository
git clone https://github.com/Glynac-AI/airflow-pipeline.git
cd airflow-pipeline

# Start the Airflow + Postgres stack
docker-compose up -d

Then follow instructions in the RUNBOOK.md to run the pipeline